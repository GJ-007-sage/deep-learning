{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GJ-007-sage/deep-learning/blob/main/Copy_of_Assignment_24b1809_GJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5df6fe2-c049-4ac2-b0f9-a637c0383601",
      "metadata": {
        "id": "a5df6fe2-c049-4ac2-b0f9-a637c0383601"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a7042b-ceb5-4112-a577-0e43b80e354c",
      "metadata": {
        "id": "08a7042b-ceb5-4112-a577-0e43b80e354c"
      },
      "outputs": [],
      "source": [
        "text = \"The universe is governed by physical laws that can be understood and described mathematically. These laws allow us to explain the phenomena we observe and predict future events. From the smallest particles to the vast expanse of galaxies, the universe operates under principles that reveal its fundamental nature.One of the most profound discoveries in modern physics is the concept of black holes. Black holes are regions of spacetime where gravity is so strong that nothing, not even light, can escape from them. They challenge our understanding of time and space, leading to questions about the very fabric of reality. Understanding black holes and their role in the cosmos could provide insights into the origins of the universe and the laws that govern it. Source: https://www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf\""
      ]
    },
    {
      "cell_type": "raw",
      "id": "4d435bf7-8d35-43fe-a29c-71efe48479f1",
      "metadata": {
        "id": "4d435bf7-8d35-43fe-a29c-71efe48479f1"
      },
      "source": [
        "1. LowerCasing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84912a5b-9bc7-42f2-a2ac-26fbdff65b35",
      "metadata": {
        "id": "84912a5b-9bc7-42f2-a2ac-26fbdff65b35",
        "outputId": "0123ff78-57da-4da7-8d02-a416587fa07f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'the universe is governed by physical laws that can be understood and described mathematically. these laws allow us to explain the phenomena we observe and predict future events. from the smallest particles to the vast expanse of galaxies, the universe operates under principles that reveal its fundamental nature.one of the most profound discoveries in modern physics is the concept of black holes. black holes are regions of spacetime where gravity is so strong that nothing, not even light, can escape from them. they challenge our understanding of time and space, leading to questions about the very fabric of reality. understanding black holes and their role in the cosmos could provide insights into the origins of the universe and the laws that govern it. source: https://www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lowercased_text = text.lower()\n",
        "\n",
        "lowercased_text"
      ]
    },
    {
      "cell_type": "raw",
      "id": "f14a26a8-6312-40a2-a13d-b79f900fa780",
      "metadata": {
        "id": "f14a26a8-6312-40a2-a13d-b79f900fa780"
      },
      "source": [
        "2. removing punctuation and special characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a868bf-f310-49c9-9d56-62011ce06022",
      "metadata": {
        "id": "82a868bf-f310-49c9-9d56-62011ce06022",
        "outputId": "c7787818-bfc7-4d38-8df4-2e71ecc65357"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The universe is governed by physical laws that can be understood and described mathematically These laws allow us to explain the phenomena we observe and predict future events From the smallest particles to the vast expanse of galaxies the universe operates under principles that reveal its fundamental natureOne of the most profound discoveries in modern physics is the concept of black holes Black holes are regions of spacetime where gravity is so strong that nothing not even light can escape from them They challenge our understanding of time and space leading to questions about the very fabric of reality Understanding black holes and their role in the cosmos could provide insights into the origins of the universe and the laws that govern it Source httpswwwfisicanetrelatividadestephen_hawking_a_brief_history_of_timepdf'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "punctuation_pattern = r'[^\\w\\s]'\n",
        "text_cleaned = re.sub(punctuation_pattern, '', text)\n",
        "text_cleaned"
      ]
    },
    {
      "cell_type": "raw",
      "id": "8d0fdbb4-66d1-4943-a78e-ecd46a1fe855",
      "metadata": {
        "id": "8d0fdbb4-66d1-4943-a78e-ecd46a1fe855"
      },
      "source": [
        "3. Stop words removal & tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0efe3261-cb50-48c3-b1a4-a67372c7bc22",
      "metadata": {
        "id": "0efe3261-cb50-48c3-b1a4-a67372c7bc22",
        "outputId": "5735644e-1233-4a86-ba7f-407c3333d525"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to C:\\Users\\Guru Jahnavi\n",
            "[nltk_data]     Madana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88e0c2e-9ec1-4f05-a6e6-f8fe4acc37ff",
      "metadata": {
        "id": "c88e0c2e-9ec1-4f05-a6e6-f8fe4acc37ff"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ffb4a8a-9e18-46cb-ab70-ca1d9c77e971",
      "metadata": {
        "id": "5ffb4a8a-9e18-46cb-ab70-ca1d9c77e971",
        "outputId": "a5b957f8-35fd-435f-bb5f-236ce9e9af3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'mustn', 'when', 'my', 'each', 'as', 've', 'being', 'were', 'ma', 'having', 'shouldn', 'shan', \"didn't\", 'we', 'which', 'haven', 'itself', \"you'd\", 'again', 'isn', 'them', 'then', 'aren', 'all', 'its', 'her', 'from', \"haven't\", 'him', 'same', 'will', 'has', 'yours', 'wasn', \"you've\", 'so', 'what', 'off', 'didn', 'into', 'mightn', 'at', 'after', 'hasn', 'there', 'own', 'won', 'few', 'where', \"isn't\", 'down', 'on', 'once', 'over', 'because', \"won't\", 'how', 'no', 'until', \"mustn't\", 'y', 'ain', 'more', 'during', 'against', 'himself', 'their', 'theirs', 'through', 'couldn', 'they', \"weren't\", \"shouldn't\", \"hadn't\", 'but', 'be', 'below', 'just', 'for', 'above', 'your', 'had', 'doing', 'before', 'and', 'most', 'further', 'other', 'needn', 'can', \"needn't\", 'between', 'any', \"don't\", 'is', 'you', 'hers', 're', \"mightn't\", 'm', \"it's\", 'these', 'up', \"you're\", 'not', 'should', 'here', 'than', 'nor', 'myself', \"that'll\", 'been', 'whom', \"should've\", \"you'll\", 'in', 'this', 'was', 'doesn', 'herself', 'too', 'll', 'have', 'who', 'our', 's', \"she's\", 'me', 'd', 'a', 'did', 'are', 'of', 'that', 'under', 'i', \"hasn't\", 'if', 'it', 'o', \"wouldn't\", 'am', 't', \"wasn't\", 'those', 'weren', 'such', 'does', 'to', 'now', 'he', 'the', \"aren't\", 'while', 'don', 'his', 'very', 'why', 'only', 'yourself', 'hadn', 'do', \"couldn't\", 'out', 'some', 'themselves', \"doesn't\", \"shan't\", 'ours', 'ourselves', 'with', 'about', 'yourselves', 'an', 'by', 'both', 'or', 'she', 'wouldn'}\n"
          ]
        }
      ],
      "source": [
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb99e5f-7dd4-4872-9b24-0fbaf88238ee",
      "metadata": {
        "id": "3fb99e5f-7dd4-4872-9b24-0fbaf88238ee",
        "outputId": "3a984b8b-5198-4d5f-9cd6-caf31d758b6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to C:\\Users\\Guru Jahnavi\n",
            "[nltk_data]     Madana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc2d07ef-f509-4134-9b75-159f2b9727e5",
      "metadata": {
        "id": "cc2d07ef-f509-4134-9b75-159f2b9727e5"
      },
      "outputs": [],
      "source": [
        "tokenize_words = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "252b0a9a-da30-4bb0-a746-ed0a053ee34c",
      "metadata": {
        "id": "252b0a9a-da30-4bb0-a746-ed0a053ee34c",
        "outputId": "c7390407-13f3-4276-afdd-ff8103947d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'universe', 'is', 'governed', 'by', 'physical', 'laws', 'that', 'can', 'be', 'understood', 'and', 'described', 'mathematically', '.', 'These', 'laws', 'allow', 'us', 'to', 'explain', 'the', 'phenomena', 'we', 'observe', 'and', 'predict', 'future', 'events', '.', 'From', 'the', 'smallest', 'particles', 'to', 'the', 'vast', 'expanse', 'of', 'galaxies', ',', 'the', 'universe', 'operates', 'under', 'principles', 'that', 'reveal', 'its', 'fundamental', 'nature.One', 'of', 'the', 'most', 'profound', 'discoveries', 'in', 'modern', 'physics', 'is', 'the', 'concept', 'of', 'black', 'holes', '.', 'Black', 'holes', 'are', 'regions', 'of', 'spacetime', 'where', 'gravity', 'is', 'so', 'strong', 'that', 'nothing', ',', 'not', 'even', 'light', ',', 'can', 'escape', 'from', 'them', '.', 'They', 'challenge', 'our', 'understanding', 'of', 'time', 'and', 'space', ',', 'leading', 'to', 'questions', 'about', 'the', 'very', 'fabric', 'of', 'reality', '.', 'Understanding', 'black', 'holes', 'and', 'their', 'role', 'in', 'the', 'cosmos', 'could', 'provide', 'insights', 'into', 'the', 'origins', 'of', 'the', 'universe', 'and', 'the', 'laws', 'that', 'govern', 'it', '.', 'Source', ':', 'https', ':', '//www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf']\n"
          ]
        }
      ],
      "source": [
        "print(tokenize_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "435dd4a5-e873-47ef-85c1-021beff7c4a8",
      "metadata": {
        "id": "435dd4a5-e873-47ef-85c1-021beff7c4a8",
        "outputId": "3761af05-35e9-41d9-ea36-db68a224de11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'universe',\n",
              " 'is',\n",
              " 'governed',\n",
              " 'by',\n",
              " 'physical',\n",
              " 'laws',\n",
              " 'that',\n",
              " 'can',\n",
              " 'be',\n",
              " 'understood',\n",
              " 'and',\n",
              " 'described',\n",
              " 'mathematically.',\n",
              " 'These',\n",
              " 'laws',\n",
              " 'allow',\n",
              " 'us',\n",
              " 'to',\n",
              " 'explain',\n",
              " 'the',\n",
              " 'phenomena',\n",
              " 'we',\n",
              " 'observe',\n",
              " 'and',\n",
              " 'predict',\n",
              " 'future',\n",
              " 'events.',\n",
              " 'From',\n",
              " 'the',\n",
              " 'smallest',\n",
              " 'particles',\n",
              " 'to',\n",
              " 'the',\n",
              " 'vast',\n",
              " 'expanse',\n",
              " 'of',\n",
              " 'galaxies,',\n",
              " 'the',\n",
              " 'universe',\n",
              " 'operates',\n",
              " 'under',\n",
              " 'principles',\n",
              " 'that',\n",
              " 'reveal',\n",
              " 'its',\n",
              " 'fundamental',\n",
              " 'nature.One',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'profound',\n",
              " 'discoveries',\n",
              " 'in',\n",
              " 'modern',\n",
              " 'physics',\n",
              " 'is',\n",
              " 'the',\n",
              " 'concept',\n",
              " 'of',\n",
              " 'black',\n",
              " 'holes.',\n",
              " 'Black',\n",
              " 'holes',\n",
              " 'are',\n",
              " 'regions',\n",
              " 'of',\n",
              " 'spacetime',\n",
              " 'where',\n",
              " 'gravity',\n",
              " 'is',\n",
              " 'so',\n",
              " 'strong',\n",
              " 'that',\n",
              " 'nothing,',\n",
              " 'not',\n",
              " 'even',\n",
              " 'light,',\n",
              " 'can',\n",
              " 'escape',\n",
              " 'from',\n",
              " 'them.',\n",
              " 'They',\n",
              " 'challenge',\n",
              " 'our',\n",
              " 'understanding',\n",
              " 'of',\n",
              " 'time',\n",
              " 'and',\n",
              " 'space,',\n",
              " 'leading',\n",
              " 'to',\n",
              " 'questions',\n",
              " 'about',\n",
              " 'the',\n",
              " 'very',\n",
              " 'fabric',\n",
              " 'of',\n",
              " 'reality.',\n",
              " 'Understanding',\n",
              " 'black',\n",
              " 'holes',\n",
              " 'and',\n",
              " 'their',\n",
              " 'role',\n",
              " 'in',\n",
              " 'the',\n",
              " 'cosmos',\n",
              " 'could',\n",
              " 'provide',\n",
              " 'insights',\n",
              " 'into',\n",
              " 'the',\n",
              " 'origins',\n",
              " 'of',\n",
              " 'the',\n",
              " 'universe',\n",
              " 'and',\n",
              " 'the',\n",
              " 'laws',\n",
              " 'that',\n",
              " 'govern',\n",
              " 'it.',\n",
              " 'Source:',\n",
              " 'https://www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens = text.split()\n",
        "word_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3045c2c-6b90-498f-be2a-fb1f50cef3c5",
      "metadata": {
        "id": "b3045c2c-6b90-498f-be2a-fb1f50cef3c5",
        "outputId": "28a9854c-3fc1-48cf-95c8-e9cc7da540ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Text: ['The', 'universe', 'governed', 'physical', 'laws', 'understood', 'described', 'mathematically.', 'These', 'laws', 'allow', 'us', 'explain', 'phenomena', 'observe', 'predict', 'future', 'events.', 'From', 'smallest', 'particles', 'vast', 'expanse', 'galaxies,', 'universe', 'operates', 'principles', 'reveal', 'fundamental', 'nature.One', 'profound', 'discoveries', 'modern', 'physics', 'concept', 'black', 'holes.', 'Black', 'holes', 'regions', 'spacetime', 'gravity', 'strong', 'nothing,', 'even', 'light,', 'escape', 'them.', 'They', 'challenge', 'understanding', 'time', 'space,', 'leading', 'questions', 'fabric', 'reality.', 'Understanding', 'black', 'holes', 'role', 'cosmos', 'could', 'provide', 'insights', 'origins', 'universe', 'laws', 'govern', 'it.', 'Source:', 'https://www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf']\n"
          ]
        }
      ],
      "source": [
        "filtered_text = [word for word in word_tokens if word not in stop_words]\n",
        "print(\"Filtered Text:\", filtered_text)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "28406499-08b5-43d3-8cb3-fd8080af68dd",
      "metadata": {
        "id": "28406499-08b5-43d3-8cb3-fd8080af68dd"
      },
      "source": [
        "4. Removal of URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f69f530-1ad0-4dd9-a255-7dccb799a1a4",
      "metadata": {
        "id": "7f69f530-1ad0-4dd9-a255-7dccb799a1a4"
      },
      "outputs": [],
      "source": [
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2910b3-066e-4438-80d9-1c204dcd20b7",
      "metadata": {
        "id": "cd2910b3-066e-4438-80d9-1c204dcd20b7",
        "outputId": "b68121a8-6f05-4484-9318-15f7d71e5259"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The universe is governed by physical laws that can be understood and described mathematically. These laws allow us to explain the phenomena we observe and predict future events. From the smallest particles to the vast expanse of galaxies, the universe operates under principles that reveal its fundamental nature.One of the most profound discoveries in modern physics is the concept of black holes. Black holes are regions of spacetime where gravity is so strong that nothing, not even light, can escape from them. They challenge our understanding of time and space, leading to questions about the very fabric of reality. Understanding black holes and their role in the cosmos could provide insights into the origins of the universe and the laws that govern it. Source: '"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "remove_urls(text)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "f3bf3c33-a26f-4aee-862f-fb0b4ad44a31",
      "metadata": {
        "id": "f3bf3c33-a26f-4aee-862f-fb0b4ad44a31"
      },
      "source": [
        "5. Removal of Html tags - no html tags in my corpus. So consider the following text2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3696a8a2-beb0-4e3d-b158-1eec3cbaeffa",
      "metadata": {
        "id": "3696a8a2-beb0-4e3d-b158-1eec3cbaeffa"
      },
      "outputs": [],
      "source": [
        "text2 = \"\"\"\n",
        "<h1>Myself an enthusiastic coder</h1>\n",
        "<p>The bootcamp is fun</p>\n",
        "<a href=\"https://example.com\"></a>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac5b7f9-94b6-44e6-a649-c898b7bcddfd",
      "metadata": {
        "id": "7ac5b7f9-94b6-44e6-a649-c898b7bcddfd",
        "outputId": "4d13d72e-2f08-4a72-ba38-243bcbf172e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nMyself an enthusiastic coder\\nThe bootcamp is fun\\n\\n'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "html_tags_pattern = r'<.*?>'\n",
        "text_without_html_tags = re.sub(html_tags_pattern, '', text2)\n",
        "text_without_html_tags"
      ]
    },
    {
      "cell_type": "raw",
      "id": "a5ef6db9-ba4a-4258-a193-2b25280b8424",
      "metadata": {
        "id": "a5ef6db9-ba4a-4258-a193-2b25280b8424"
      },
      "source": [
        "6. stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7537bfa1-bcc4-47d9-be2c-87c9e143ab0d",
      "metadata": {
        "id": "7537bfa1-bcc4-47d9-be2c-87c9e143ab0d"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bfca5d0-f966-4f92-94e4-ce500fd2a0ae",
      "metadata": {
        "id": "3bfca5d0-f966-4f92-94e4-ce500fd2a0ae"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02077fd-3ae2-4ffa-b7ae-cf64b54191b4",
      "metadata": {
        "id": "e02077fd-3ae2-4ffa-b7ae-cf64b54191b4"
      },
      "outputs": [],
      "source": [
        "def stem_words(text):\n",
        "    word_tokens = text.split()\n",
        "    stems = [stemmer.stem(word) for word in word_tokens]\n",
        "    return stems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2db44fd-eebb-4fcd-a033-a54bf4144aba",
      "metadata": {
        "id": "d2db44fd-eebb-4fcd-a033-a54bf4144aba",
        "outputId": "3192bb5b-ca62-4891-b2d2-67c3b3b1e8e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the',\n",
              " 'univers',\n",
              " 'is',\n",
              " 'govern',\n",
              " 'by',\n",
              " 'physic',\n",
              " 'law',\n",
              " 'that',\n",
              " 'can',\n",
              " 'be',\n",
              " 'understood',\n",
              " 'and',\n",
              " 'describ',\n",
              " 'mathematically.',\n",
              " 'these',\n",
              " 'law',\n",
              " 'allow',\n",
              " 'us',\n",
              " 'to',\n",
              " 'explain',\n",
              " 'the',\n",
              " 'phenomena',\n",
              " 'we',\n",
              " 'observ',\n",
              " 'and',\n",
              " 'predict',\n",
              " 'futur',\n",
              " 'events.',\n",
              " 'from',\n",
              " 'the',\n",
              " 'smallest',\n",
              " 'particl',\n",
              " 'to',\n",
              " 'the',\n",
              " 'vast',\n",
              " 'expans',\n",
              " 'of',\n",
              " 'galaxies,',\n",
              " 'the',\n",
              " 'univers',\n",
              " 'oper',\n",
              " 'under',\n",
              " 'principl',\n",
              " 'that',\n",
              " 'reveal',\n",
              " 'it',\n",
              " 'fundament',\n",
              " 'nature.on',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'profound',\n",
              " 'discoveri',\n",
              " 'in',\n",
              " 'modern',\n",
              " 'physic',\n",
              " 'is',\n",
              " 'the',\n",
              " 'concept',\n",
              " 'of',\n",
              " 'black',\n",
              " 'holes.',\n",
              " 'black',\n",
              " 'hole',\n",
              " 'are',\n",
              " 'region',\n",
              " 'of',\n",
              " 'spacetim',\n",
              " 'where',\n",
              " 'graviti',\n",
              " 'is',\n",
              " 'so',\n",
              " 'strong',\n",
              " 'that',\n",
              " 'nothing,',\n",
              " 'not',\n",
              " 'even',\n",
              " 'light,',\n",
              " 'can',\n",
              " 'escap',\n",
              " 'from',\n",
              " 'them.',\n",
              " 'they',\n",
              " 'challeng',\n",
              " 'our',\n",
              " 'understand',\n",
              " 'of',\n",
              " 'time',\n",
              " 'and',\n",
              " 'space,',\n",
              " 'lead',\n",
              " 'to',\n",
              " 'question',\n",
              " 'about',\n",
              " 'the',\n",
              " 'veri',\n",
              " 'fabric',\n",
              " 'of',\n",
              " 'reality.',\n",
              " 'understand',\n",
              " 'black',\n",
              " 'hole',\n",
              " 'and',\n",
              " 'their',\n",
              " 'role',\n",
              " 'in',\n",
              " 'the',\n",
              " 'cosmo',\n",
              " 'could',\n",
              " 'provid',\n",
              " 'insight',\n",
              " 'into',\n",
              " 'the',\n",
              " 'origin',\n",
              " 'of',\n",
              " 'the',\n",
              " 'univers',\n",
              " 'and',\n",
              " 'the',\n",
              " 'law',\n",
              " 'that',\n",
              " 'govern',\n",
              " 'it.',\n",
              " 'source:',\n",
              " 'https://www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stem_words(text)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "d1220010-75a7-4c44-a3b9-16e8728fc075",
      "metadata": {
        "id": "d1220010-75a7-4c44-a3b9-16e8728fc075"
      },
      "source": [
        "7. Lemmatisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f6873f7-2d80-4478-8887-04bbe3f0fc0c",
      "metadata": {
        "id": "8f6873f7-2d80-4478-8887-04bbe3f0fc0c",
        "outputId": "872c83cc-66a0-42fa-b4b9-5edc3191c0cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to C:\\Users\\Guru Jahnavi\n",
            "[nltk_data]     Madana\\AppData\\Roaming\\nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89143ba6-325b-4ac0-9d71-a0fab6f9e16b",
      "metadata": {
        "id": "89143ba6-325b-4ac0-9d71-a0fab6f9e16b"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cba5db3-1e41-4b4b-b729-67ca78db2874",
      "metadata": {
        "id": "2cba5db3-1e41-4b4b-b729-67ca78db2874"
      },
      "outputs": [],
      "source": [
        "def lemmatize_word(text):\n",
        "    word_tokens = text.split()\n",
        "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens]\n",
        "    return lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "add774b8-7484-4760-b875-8eb713f8069e",
      "metadata": {
        "id": "add774b8-7484-4760-b875-8eb713f8069e",
        "outputId": "f28fe87a-4470-42ea-e886-cbcf7c72bc5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'universe',\n",
              " 'be',\n",
              " 'govern',\n",
              " 'by',\n",
              " 'physical',\n",
              " 'laws',\n",
              " 'that',\n",
              " 'can',\n",
              " 'be',\n",
              " 'understand',\n",
              " 'and',\n",
              " 'describe',\n",
              " 'mathematically.',\n",
              " 'These',\n",
              " 'laws',\n",
              " 'allow',\n",
              " 'us',\n",
              " 'to',\n",
              " 'explain',\n",
              " 'the',\n",
              " 'phenomena',\n",
              " 'we',\n",
              " 'observe',\n",
              " 'and',\n",
              " 'predict',\n",
              " 'future',\n",
              " 'events.',\n",
              " 'From',\n",
              " 'the',\n",
              " 'smallest',\n",
              " 'particles',\n",
              " 'to',\n",
              " 'the',\n",
              " 'vast',\n",
              " 'expanse',\n",
              " 'of',\n",
              " 'galaxies,',\n",
              " 'the',\n",
              " 'universe',\n",
              " 'operate',\n",
              " 'under',\n",
              " 'principles',\n",
              " 'that',\n",
              " 'reveal',\n",
              " 'its',\n",
              " 'fundamental',\n",
              " 'nature.One',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'profound',\n",
              " 'discoveries',\n",
              " 'in',\n",
              " 'modern',\n",
              " 'physics',\n",
              " 'be',\n",
              " 'the',\n",
              " 'concept',\n",
              " 'of',\n",
              " 'black',\n",
              " 'holes.',\n",
              " 'Black',\n",
              " 'hole',\n",
              " 'be',\n",
              " 'regions',\n",
              " 'of',\n",
              " 'spacetime',\n",
              " 'where',\n",
              " 'gravity',\n",
              " 'be',\n",
              " 'so',\n",
              " 'strong',\n",
              " 'that',\n",
              " 'nothing,',\n",
              " 'not',\n",
              " 'even',\n",
              " 'light,',\n",
              " 'can',\n",
              " 'escape',\n",
              " 'from',\n",
              " 'them.',\n",
              " 'They',\n",
              " 'challenge',\n",
              " 'our',\n",
              " 'understand',\n",
              " 'of',\n",
              " 'time',\n",
              " 'and',\n",
              " 'space,',\n",
              " 'lead',\n",
              " 'to',\n",
              " 'question',\n",
              " 'about',\n",
              " 'the',\n",
              " 'very',\n",
              " 'fabric',\n",
              " 'of',\n",
              " 'reality.',\n",
              " 'Understanding',\n",
              " 'black',\n",
              " 'hole',\n",
              " 'and',\n",
              " 'their',\n",
              " 'role',\n",
              " 'in',\n",
              " 'the',\n",
              " 'cosmos',\n",
              " 'could',\n",
              " 'provide',\n",
              " 'insights',\n",
              " 'into',\n",
              " 'the',\n",
              " 'origins',\n",
              " 'of',\n",
              " 'the',\n",
              " 'universe',\n",
              " 'and',\n",
              " 'the',\n",
              " 'laws',\n",
              " 'that',\n",
              " 'govern',\n",
              " 'it.',\n",
              " 'Source:',\n",
              " 'https://www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatize_word(text)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "edb098de-89ed-43bb-8f98-b502267188e2",
      "metadata": {
        "id": "edb098de-89ed-43bb-8f98-b502267188e2"
      },
      "source": [
        "8. Tokenise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51440236-c1b1-4773-9c8d-4eb67043d596",
      "metadata": {
        "id": "51440236-c1b1-4773-9c8d-4eb67043d596",
        "outputId": "322ccc67-8c62-4a5c-865d-8ba72f4b2431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'universe', 'is', 'governed', 'by', 'physical', 'laws', 'that', 'can', 'be', 'understood', 'and', 'described', 'mathematically', '.', 'These', 'laws', 'allow', 'us', 'to', 'explain', 'the', 'phenomena', 'we', 'observe', 'and', 'predict', 'future', 'events', '.', 'From', 'the', 'smallest', 'particles', 'to', 'the', 'vast', 'expanse', 'of', 'galaxies', ',', 'the', 'universe', 'operates', 'under', 'principles', 'that', 'reveal', 'its', 'fundamental', 'nature.One', 'of', 'the', 'most', 'profound', 'discoveries', 'in', 'modern', 'physics', 'is', 'the', 'concept', 'of', 'black', 'holes', '.', 'Black', 'holes', 'are', 'regions', 'of', 'spacetime', 'where', 'gravity', 'is', 'so', 'strong', 'that', 'nothing', ',', 'not', 'even', 'light', ',', 'can', 'escape', 'from', 'them', '.', 'They', 'challenge', 'our', 'understanding', 'of', 'time', 'and', 'space', ',', 'leading', 'to', 'questions', 'about', 'the', 'very', 'fabric', 'of', 'reality', '.', 'Understanding', 'black', 'holes', 'and', 'their', 'role', 'in', 'the', 'cosmos', 'could', 'provide', 'insights', 'into', 'the', 'origins', 'of', 'the', 'universe', 'and', 'the', 'laws', 'that', 'govern', 'it', '.', 'Source', ':', 'https', ':', '//www.fisica.net/relatividade/stephen_hawking_a_brief_history_of_time.pdf']\n"
          ]
        }
      ],
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "c77dbe70-d92f-42ca-b387-2a2912566760",
      "metadata": {
        "id": "c77dbe70-d92f-42ca-b387-2a2912566760"
      },
      "source": [
        "9. Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea089c8-c09d-465a-bae6-ab674f0635e8",
      "metadata": {
        "id": "9ea089c8-c09d-465a-bae6-ab674f0635e8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c13720-0849-4dc8-8fff-a6d5a1990ed0",
      "metadata": {
        "id": "a9c13720-0849-4dc8-8fff-a6d5a1990ed0"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "X_array = X.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1558d42-9272-4cf7-9f8e-f7d52b6d2307",
      "metadata": {
        "id": "d1558d42-9272-4cf7-9f8e-f7d52b6d2307",
        "outputId": "24a4f8bc-29eb-4db8-d288-f83c80327866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique Word List: \n",
            " ['allow' 'black' 'challenge' 'concept' 'cosmos' 'could' 'described'\n",
            " 'discovery' 'escape' 'even' 'events' 'expanse' 'explain' 'fabric' 'from'\n",
            " 'fundamental' 'future' 'galaxies' 'govern' 'governed' 'gravity' 'hole'\n",
            " 'holes'\n",
            " 'httpswwwfisicanetrelatividadestephen_hawking_a_brief_history_of_timepdf'\n",
            " 'insight' 'it' 'law' 'leading' 'light' 'mathematically' 'modern'\n",
            " 'natureone' 'nothing' 'observe' 'operates' 'origin' 'particle'\n",
            " 'phenomenon' 'physic' 'physical' 'predict' 'principle' 'profound'\n",
            " 'provide' 'question' 'reality' 'region' 'reveal' 'role' 'smallest'\n",
            " 'source' 'space' 'spacetime' 'strong' 'the' 'them' 'these' 'they' 'time'\n",
            " 'understanding' 'understood' 'universe' 'vast']\n",
            "Bag of Words Matrix: \n",
            " [[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
            "  0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0\n",
            "  1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
            " [0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0]\n",
            " [0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Unique Word List: \\n\", feature_names)\n",
        "print(\"Bag of Words Matrix: \\n\", X_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb3468c-c43f-4b55-84a1-77a567faee06",
      "metadata": {
        "id": "0cb3468c-c43f-4b55-84a1-77a567faee06"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ca62c4-8cad-4595-a027-1fb2ddf4ee77",
      "metadata": {
        "id": "d7ca62c4-8cad-4595-a027-1fb2ddf4ee77",
        "outputId": "8dc13bcd-9992-4eac-ee27-e157aca985d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>allow</th>\n",
              "      <th>black</th>\n",
              "      <th>challenge</th>\n",
              "      <th>concept</th>\n",
              "      <th>cosmos</th>\n",
              "      <th>could</th>\n",
              "      <th>described</th>\n",
              "      <th>discovery</th>\n",
              "      <th>escape</th>\n",
              "      <th>even</th>\n",
              "      <th>...</th>\n",
              "      <th>strong</th>\n",
              "      <th>the</th>\n",
              "      <th>them</th>\n",
              "      <th>these</th>\n",
              "      <th>they</th>\n",
              "      <th>time</th>\n",
              "      <th>understanding</th>\n",
              "      <th>understood</th>\n",
              "      <th>universe</th>\n",
              "      <th>vast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the universe governed physical law understood described mathematically</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>these law allow u explain phenomenon observe predict future events</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from smallest particle vast expanse galaxies universe operates principle reveal fundamental natureone profound discovery modern physic concept black holes</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>black hole region spacetime gravity strong nothing even light escape them</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>they challenge understanding time space leading question fabric reality</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>understanding black hole role cosmos could provide insight origin universe law govern it</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source httpswwwfisicanetrelatividadestephen_hawking_a_brief_history_of_timepdf</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 63 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    allow  black  challenge  \\\n",
              "the universe governed physical law understood d...      0      0          0   \n",
              "these law allow u explain phenomenon observe pr...      1      0          0   \n",
              "from smallest particle vast expanse galaxies un...      0      1          0   \n",
              "black hole region spacetime gravity strong noth...      0      1          0   \n",
              "they challenge understanding time space leading...      0      0          1   \n",
              "understanding black hole role cosmos could prov...      0      1          0   \n",
              "source httpswwwfisicanetrelatividadestephen_haw...      0      0          0   \n",
              "\n",
              "                                                    concept  cosmos  could  \\\n",
              "the universe governed physical law understood d...        0       0      0   \n",
              "these law allow u explain phenomenon observe pr...        0       0      0   \n",
              "from smallest particle vast expanse galaxies un...        1       0      0   \n",
              "black hole region spacetime gravity strong noth...        0       0      0   \n",
              "they challenge understanding time space leading...        0       0      0   \n",
              "understanding black hole role cosmos could prov...        0       1      1   \n",
              "source httpswwwfisicanetrelatividadestephen_haw...        0       0      0   \n",
              "\n",
              "                                                    described  discovery  \\\n",
              "the universe governed physical law understood d...          1          0   \n",
              "these law allow u explain phenomenon observe pr...          0          0   \n",
              "from smallest particle vast expanse galaxies un...          0          1   \n",
              "black hole region spacetime gravity strong noth...          0          0   \n",
              "they challenge understanding time space leading...          0          0   \n",
              "understanding black hole role cosmos could prov...          0          0   \n",
              "source httpswwwfisicanetrelatividadestephen_haw...          0          0   \n",
              "\n",
              "                                                    escape  even  ...  strong  \\\n",
              "the universe governed physical law understood d...       0     0  ...       0   \n",
              "these law allow u explain phenomenon observe pr...       0     0  ...       0   \n",
              "from smallest particle vast expanse galaxies un...       0     0  ...       0   \n",
              "black hole region spacetime gravity strong noth...       1     1  ...       1   \n",
              "they challenge understanding time space leading...       0     0  ...       0   \n",
              "understanding black hole role cosmos could prov...       0     0  ...       0   \n",
              "source httpswwwfisicanetrelatividadestephen_haw...       0     0  ...       0   \n",
              "\n",
              "                                                    the  them  these  they  \\\n",
              "the universe governed physical law understood d...    1     0      0     0   \n",
              "these law allow u explain phenomenon observe pr...    0     0      1     0   \n",
              "from smallest particle vast expanse galaxies un...    0     0      0     0   \n",
              "black hole region spacetime gravity strong noth...    0     1      0     0   \n",
              "they challenge understanding time space leading...    0     0      0     1   \n",
              "understanding black hole role cosmos could prov...    0     0      0     0   \n",
              "source httpswwwfisicanetrelatividadestephen_haw...    0     0      0     0   \n",
              "\n",
              "                                                    time  understanding  \\\n",
              "the universe governed physical law understood d...     0              0   \n",
              "these law allow u explain phenomenon observe pr...     0              0   \n",
              "from smallest particle vast expanse galaxies un...     0              0   \n",
              "black hole region spacetime gravity strong noth...     0              0   \n",
              "they challenge understanding time space leading...     1              1   \n",
              "understanding black hole role cosmos could prov...     0              1   \n",
              "source httpswwwfisicanetrelatividadestephen_haw...     0              0   \n",
              "\n",
              "                                                    understood  universe  vast  \n",
              "the universe governed physical law understood d...           1         1     0  \n",
              "these law allow u explain phenomenon observe pr...           0         0     0  \n",
              "from smallest particle vast expanse galaxies un...           0         1     1  \n",
              "black hole region spacetime gravity strong noth...           0         0     0  \n",
              "they challenge understanding time space leading...           0         0     0  \n",
              "understanding black hole role cosmos could prov...           0         1     0  \n",
              "source httpswwwfisicanetrelatividadestephen_haw...           0         0     0  \n",
              "\n",
              "[7 rows x 63 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(data=X_array, columns=feature_names, index=corpus)\n",
        "(df)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "f948c505-c3f3-4f5d-9c13-e99c8164a827",
      "metadata": {
        "id": "f948c505-c3f3-4f5d-9c13-e99c8164a827"
      },
      "source": [
        "10. TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bffc598-ed4a-44dc-af50-ddde96cff72b",
      "metadata": {
        "id": "9bffc598-ed4a-44dc-af50-ddde96cff72b"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7debc2-5ace-4cc9-8c5b-d1b9c2b05d94",
      "metadata": {
        "id": "0d7debc2-5ace-4cc9-8c5b-d1b9c2b05d94",
        "outputId": "b7b7d90f-92ca-43ca-c071-0b8abc98a549"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>allow</th>\n",
              "      <th>black</th>\n",
              "      <th>challenge</th>\n",
              "      <th>concept</th>\n",
              "      <th>cosmos</th>\n",
              "      <th>could</th>\n",
              "      <th>described</th>\n",
              "      <th>discovery</th>\n",
              "      <th>escape</th>\n",
              "      <th>even</th>\n",
              "      <th>...</th>\n",
              "      <th>strong</th>\n",
              "      <th>the</th>\n",
              "      <th>them</th>\n",
              "      <th>these</th>\n",
              "      <th>they</th>\n",
              "      <th>time</th>\n",
              "      <th>understanding</th>\n",
              "      <th>understood</th>\n",
              "      <th>universe</th>\n",
              "      <th>vast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.377779</td>\n",
              "      <td>0.268046</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.342928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.342928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.167206</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.235657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.235657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.167206</td>\n",
              "      <td>0.235657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222244</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.313228</td>\n",
              "      <td>0.313228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.313228</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.313228</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.339245</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.339245</td>\n",
              "      <td>0.339245</td>\n",
              "      <td>0.281603</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303053</td>\n",
              "      <td>0.303053</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.251560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.215025</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 63 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      allow     black  challenge   concept    cosmos     could  described  \\\n",
              "0  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   0.377779   \n",
              "1  0.342928  0.000000   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "2  0.000000  0.167206   0.000000  0.235657  0.000000  0.000000   0.000000   \n",
              "3  0.000000  0.222244   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "4  0.000000  0.000000   0.339245  0.000000  0.000000  0.000000   0.000000   \n",
              "5  0.000000  0.215025   0.000000  0.000000  0.303053  0.303053   0.000000   \n",
              "6  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   0.000000   \n",
              "\n",
              "   discovery    escape      even  ...    strong       the      them     these  \\\n",
              "0   0.000000  0.000000  0.000000  ...  0.000000  0.377779  0.000000  0.000000   \n",
              "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.342928   \n",
              "2   0.235657  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "3   0.000000  0.313228  0.313228  ...  0.313228  0.000000  0.313228  0.000000   \n",
              "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "       they      time  understanding  understood  universe      vast  \n",
              "0  0.000000  0.000000       0.000000    0.377779  0.268046  0.000000  \n",
              "1  0.000000  0.000000       0.000000    0.000000  0.000000  0.000000  \n",
              "2  0.000000  0.000000       0.000000    0.000000  0.167206  0.235657  \n",
              "3  0.000000  0.000000       0.000000    0.000000  0.000000  0.000000  \n",
              "4  0.339245  0.339245       0.281603    0.000000  0.000000  0.000000  \n",
              "5  0.000000  0.000000       0.251560    0.000000  0.215025  0.000000  \n",
              "6  0.000000  0.000000       0.000000    0.000000  0.000000  0.000000  \n",
              "\n",
              "[7 rows x 63 columns]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "df = pd.DataFrame(tfidf_matrix.toarray(), columns=terms)\n",
        "(df)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "cba19784-9067-4c36-9cc2-c48478300712",
      "metadata": {
        "id": "cba19784-9067-4c36-9cc2-c48478300712"
      },
      "source": [
        "11. Encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18dfd9f1-ecc1-4f8f-a3ea-9cb1b0d48b41",
      "metadata": {
        "id": "18dfd9f1-ecc1-4f8f-a3ea-9cb1b0d48b41"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a457a3-a3ff-4fd8-a4b9-669bb0fe15e6",
      "metadata": {
        "id": "a9a457a3-a3ff-4fd8-a4b9-669bb0fe15e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8538776a-5578-49bc-8e99-77d001f0ccb3",
      "metadata": {
        "id": "8538776a-5578-49bc-8e99-77d001f0ccb3",
        "outputId": "a48f9844-69f9-485c-88f5-a89e5372b2f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Guru Jahnavi\n",
            "[nltk_data]     Madana\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889f30a6-cb4a-4d51-8071-09f66da8c8e2",
      "metadata": {
        "id": "889f30a6-cb4a-4d51-8071-09f66da8c8e2"
      },
      "outputs": [],
      "source": [
        "tokenized_text = [nltk.word_tokenize(sentence.lower()) for sentence in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ab62bb-1077-4a56-a793-c7167c403a50",
      "metadata": {
        "id": "c8ab62bb-1077-4a56-a793-c7167c403a50"
      },
      "outputs": [],
      "source": [
        "all_words = [word for sentence in tokenized_text for word in sentence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294b9910-211b-42c5-9d19-22be4935678b",
      "metadata": {
        "id": "294b9910-211b-42c5-9d19-22be4935678b"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(all_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c4cf625-276c-4b1c-9f8a-1dca3aa65e45",
      "metadata": {
        "id": "4c4cf625-276c-4b1c-9f8a-1dca3aa65e45",
        "outputId": "b7470841-cb46-40ea-ee4e-8706ef44e9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: [',', '.', '/', ':', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary:\", vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1f3432-b5b0-424e-bfbd-f10a63b88304",
      "metadata": {
        "id": "4b1f3432-b5b0-424e-bfbd-f10a63b88304"
      },
      "outputs": [],
      "source": [
        "word_array = np.array(all_words).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f421dae8-f7f1-4297-873c-497f10dbcbd4",
      "metadata": {
        "id": "f421dae8-f7f1-4297-873c-497f10dbcbd4"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_encoded = one_hot_encoder.fit_transform(word_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c032e6e-d233-44b7-9be0-ba78bac73feb",
      "metadata": {
        "id": "4c032e6e-d233-44b7-9be0-ba78bac73feb",
        "outputId": "018d2e17-06e3-4059-d92e-ac2e0325b00e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One-hot encoded matrix:\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(\"One-hot encoded matrix:\\n\", one_hot_encoded)"
      ]
    },
    {
      "cell_type": "raw",
      "id": "d20b330c-e35f-4e54-9412-050133348d2a",
      "metadata": {
        "id": "d20b330c-e35f-4e54-9412-050133348d2a"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}